{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP V3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "eENmFkCS9QL1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import csv\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import codecs\n",
        "from tqdm import tqdm \n",
        "from random import shuffle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import nltk\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt                                                 \n",
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zThDWGMQ9GGr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_filters, filter_sizes, dropout):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_channels = 1, out_channels = n_filters, kernel_size = (fs, embedding_dim)) for fs in filter_sizes])\n",
        "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "    \n",
        "        #x = [sent len, batch size]\n",
        "        x = x.permute(1, 0)\n",
        "                \n",
        "        #x = [batch size, sent len]\n",
        "        embedded = self.embedding(x)\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        embedded = embedded.unsqueeze(1)\n",
        "        #embedded = [batch size, 1, sent len, emb dim]\n",
        "        \n",
        "        #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "\n",
        "        #pooled_n = [batch size, n_filters]\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "        \n",
        "        #cat = [batch size, n_filters * len(filter_sizes)]\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "            \n",
        "        return self.fc(cat)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zj0tD3yB-foP",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "14965fa6-ee3d-477e-e57a-ca1ebeba6e22"
      },
      "cell_type": "code",
      "source": [
        "#Upload Files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "for k, v in uploaded.items():\n",
        "  print(k)\n",
        " \n",
        "# Supply the training tsv file and the test tsv file for subtask a"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c6e9320b-3407-4800-8317-8df4d507fbaa\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-c6e9320b-3407-4800-8317-8df4d507fbaa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving testset-taskb.tsv to testset-taskb.tsv\n",
            "Saving offenseval-training-v1.tsv to offenseval-training-v1.tsv\n",
            "testset-taskb.tsv\n",
            "offenseval-training-v1.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oJL6biIpFhkh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# #Download glove pre-trained word embeddings\n",
        "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "# !unzip glove.6B.zip\n",
        " \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HIfn7W5bjYqn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def case_normalization(msg):\n",
        "    return msg.strip().lower()\n",
        "\n",
        "def remove_delimiters(msg):\n",
        "    #stopwords = set(nltk.corpus.stopwords.words('english'))\n",
        "    #filter_func = lambda word : word not in stopwords\n",
        "    filter_func = None\n",
        "    return filter(filter_func, re.split('[ ,.!]', msg))\n",
        "\n",
        "def pre_process_msg(msg):\n",
        "    return remove_delimiters(case_normalization(msg))\n",
        "\n",
        "def parse_data(input_tsv):\n",
        "    lines = re.split('[\\n\\r]', input_tsv)\n",
        "    fields = lines[0].split('\\t')\n",
        "    data = {}\n",
        "    for field in fields:\n",
        "        data[field] = []\n",
        "    \n",
        "    shuffle(lines)\n",
        "    \n",
        "    for line in lines[1:]:\n",
        "        row = line.split('\\t')\n",
        "        if not all('' == s for s in row):\n",
        "          if row[-2] != 'NULL':\n",
        "            for i, token in enumerate(row):\n",
        "                if token:\n",
        "                    data[fields[i]].append(token)\n",
        "    return data\n",
        "\n",
        "def prepare_sequence(seq, to_index):\n",
        "    idxs = list(map(lambda w : to_index[w] if to_index.get(w) else to_index[\"<unk>\"], seq))\n",
        "    return LongTensor(idxs)\n",
        "\n",
        "def prepare_data(text, word2idx=None):\n",
        "    # Read lines and add the end of sentence symbol\n",
        "    flatten = lambda l : [item for sublist in l for item in sublist]\n",
        "    corpus = [sentence.strip().split() + ['</s>'] for sentence in text]\n",
        "\n",
        "    # Create a word to index dictionary\n",
        "    if word2idx == None:\n",
        "        vocab = flatten(corpus)\n",
        "        word2idx = {'<unk>': 0}\n",
        "        for vo in vocab:\n",
        "            if not word2idx.get(vo):\n",
        "                word2idx[vo] = len(word2idx)\n",
        "\n",
        "    #data = map(lambda sentence : prepare_sequence(sentence, word2idx), corpus)\n",
        "    data = prepare_sequence(flatten(corpus), word2idx)\n",
        "    return data, word2idx\n",
        "\n",
        "def get_word2idx(tokenized_corpus):\n",
        "    vocabulary = []\n",
        "    for sentence in tokenized_corpus:\n",
        "        for token in sentence:\n",
        "            if token not in vocabulary:\n",
        "                vocabulary.append(token)\n",
        "\n",
        "\n",
        "    word2idx = {w: idx+1 for (idx, w) in enumerate(vocabulary)}\n",
        "    # we reserve the 0 index for the placeholder token\n",
        "    word2idx['<pad>'] = 0\n",
        "\n",
        "    return word2idx\n",
        "\n",
        "def get_model_inputs(tokenized_corpus, word2idx, labels, max_len):\n",
        "    # we index our sentences\n",
        "    vectorized_sents = [[word2idx[tok] for tok in sent if tok in word2idx] for sent in tokenized_corpus]\n",
        "    # we create a tensor of a fixed size filled with zeroes for padding\n",
        "    sent_tensor = Variable(torch.zeros((len(vectorized_sents), max_len))).long()\n",
        "    sent_lengths = [len(sent) for sent in vectorized_sents]\n",
        "    # we fill it with our vectorized sentences\n",
        "    for idx, (sent, sentlen) in enumerate(zip(vectorized_sents, sent_lengths)):\n",
        "        sent_tensor[idx, :sentlen] = torch.cuda.LongTensor(sent)\n",
        "    label_tensor = torch.cuda.FloatTensor(labels)\n",
        "    return sent_tensor, label_tensor\n",
        "\n",
        "def predict_value(input_tensor):\n",
        "    prediction = torch.sigmoid(model(input_tensor))\n",
        "    return int(round(prediction.item()))\n",
        "  \n",
        "def pretrained_embeddings(embedding_dim, word2idx):\n",
        "  \n",
        "    wvecs = np.zeros((len(word2idx), embedding_dim))\n",
        "\n",
        "    with codecs.open('glove.6B.300d.txt', 'r','utf-8') as f: \n",
        "      index = 0\n",
        "      for line in tqdm(f.readlines()):\n",
        "        if len(line.strip().split()) > 3:\n",
        "          word = line.strip().split()[0]\n",
        "          if word in word2idx:\n",
        "              (word, vec) = (word, list(map(float,line.strip().split()[1:])))\n",
        "              idx = word2idx[word]\n",
        "              wvecs[idx] = vec\n",
        "\n",
        "    return wvecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oQYwv4BSbrsX",
        "colab_type": "code",
        "outputId": "f28b121e-0b9c-4963-8185-ad4683340888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3096
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  \n",
        "    # Hyperparameters\n",
        "    EMBEDDING_SIZE = 300\n",
        "    HIDDEN_LAYER_SIZE = 100\n",
        "    LR = 0.01\n",
        "    EPOCH = 15\n",
        "    OUTPUT_DIM = 1\n",
        "    N_FILTERS = 10\n",
        "    FILTER_SIZES = [3, 4, 5]\n",
        "    DROPOUT = 0.5\n",
        "    BATCH_SIZE = 100\n",
        "  \n",
        "    # Parse the csv files into appropriate datasets\n",
        "    for k, v in uploaded.items():\n",
        "      print(k)\n",
        "  \n",
        "    model_dataset = parse_data(uploaded['offenseval-training-v1.tsv'])\n",
        "    testing_dataset = parse_data(uploaded['testset-taskb.tsv'])\n",
        "\n",
        "    id_values = model_dataset['id']\n",
        "    model_corpus = map(pre_process_msg, model_dataset['tweet'])\n",
        "    testing_corpus = map(pre_process_msg, testing_dataset['tweet'])\n",
        "    off_categories = [1 if category == 'TIN' else 0 for category in model_dataset['subtask_b']]\n",
        "    \n",
        "    #Checking how balanced the dataset is\n",
        "    tin_no = 0\n",
        "    unt_no = 0\n",
        "    for category in model_dataset['subtask_b']:\n",
        "      if category == 'TIN':\n",
        "        tin_no = tin_no + 1\n",
        "      else:\n",
        "        unt_no = unt_no + 1\n",
        "    print(tin_no)\n",
        "    print(unt_no)\n",
        "    \n",
        "    break_point = len(model_corpus) // 10\n",
        "    training_corpus = model_corpus[:-break_point]\n",
        "    training_target = off_categories[:-break_point]\n",
        "    validation_corpus = model_corpus[-break_point:]\n",
        "    validation_target = off_categories[-break_point:]\n",
        "\n",
        "    # Fix seeds for consistent results\n",
        "    SEED = 234\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    random.seed(SEED)\n",
        "\n",
        "    word2idx = get_word2idx(training_corpus)\n",
        "    max_len = np.max(np.array([len(sent) for sent in training_corpus]))\n",
        "    training_data_tensor, training_label_tensor = get_model_inputs(training_corpus, word2idx, training_target, max_len)\n",
        "    validation_data_tensor, validation_label_tensor = get_model_inputs(validation_corpus, word2idx, validation_target, max_len)\n",
        "    testing_data_tensor, _ = get_model_inputs(testing_corpus, word2idx, [], max_len)\n",
        "\n",
        "    model = CNN(len(word2idx), EMBEDDING_SIZE, HIDDEN_LAYER_SIZE, OUTPUT_DIM, N_FILTERS, FILTER_SIZES, DROPOUT)\n",
        "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    \n",
        "    #Using pretrained embeddings\n",
        "#     wvecs = pretrained_embeddings(EMBEDDING_SIZE, word2idx)\n",
        "#     model.embedding.weight.data.copy_(torch.from_numpy(wvecs))\n",
        "\n",
        "    loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # In this class we will make use of the optimizer refer: https://pytorch.org/docs/stable/optim.html for details\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "    for epoch in range(EPOCH):\n",
        "        print(\"On epoch \" + str(epoch + 1) + \" out of \" + str(EPOCH))\n",
        "        total_loss = 0\n",
        "        losses = []\n",
        "        model.train()\n",
        "        print(\"Starting batch loop...\")\n",
        "        for i in range(0, len(training_data_tensor), BATCH_SIZE):\n",
        "     \n",
        "            model.zero_grad()\n",
        "            inputs = training_data_tensor[i : i + BATCH_SIZE].permute(1, 0).to(device)\n",
        "            targets = training_label_tensor[i : i + BATCH_SIZE].unsqueeze(1).to(device)\n",
        "            preds = model(inputs)\n",
        "            loss = loss_function(preds, targets)\n",
        "            losses.append(loss.item())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            if i > 0 and i % 500 == 0:\n",
        "                print(\"[%02d/%d] mean_loss : %0.2f, Perplexity : %0.2f\" % ((epoch + 1), EPOCH, np.mean(losses), np.exp(np.mean(losses))))\n",
        "                losses = []\n",
        "        print(\"Finished batch loop...\")\n",
        "\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    print(\"PREDICTING LABELS NOW\")\n",
        "    for validation_input in validation_data_tensor:\n",
        "        model.zero_grad()\n",
        "        predicted_label = predict_value(validation_input.unsqueeze(1).to(device))\n",
        "        preds.append(predicted_label)\n",
        "    print(\"FINISHED PREDICTING LABELS\")\n",
        "\n",
        "    # Temporary plot of Confusion Matrix\n",
        "    acc = accuracy_score(validation_target, preds)\n",
        "    f1 = f1_score(validation_target, preds, average = 'macro') \n",
        "    print(\"Accuracy:\")\n",
        "    print(acc)\n",
        "    print(\"F1:\")\n",
        "    print(f1)\n",
        "    cm = confusion_matrix(validation_target, preds)\n",
        "    plt.clf()\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Wistia)\n",
        "    classNames = ['Negative','Positive']\n",
        "    tick_marks = np.arange(len(classNames))\n",
        "    plt.xticks(tick_marks, classNames)\n",
        "    plt.yticks(tick_marks, classNames)\n",
        "    plt.title('Targeted or Untargeted Confusion Matrix - Test Data')\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    s = [['TN','FP'], ['FN', 'TP']]\n",
        "    for i in range(2):\n",
        "       for j in range(2):\n",
        "           plt.text(j, i, str(cm[i][j]))\n",
        "    plt.show()\n",
        "    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testset-taskb.tsv\n",
            "offenseval-training-v1.tsv\n",
            "3876\n",
            "525\n",
            "On epoch 1 out of 15\n",
            "Starting batch loop...\n",
            "[01/15] mean_loss : 0.54, Perplexity : 1.71\n",
            "[01/15] mean_loss : 0.36, Perplexity : 1.43\n",
            "[01/15] mean_loss : 0.40, Perplexity : 1.49\n",
            "[01/15] mean_loss : 0.37, Perplexity : 1.45\n",
            "[01/15] mean_loss : 0.43, Perplexity : 1.53\n",
            "[01/15] mean_loss : 0.39, Perplexity : 1.48\n",
            "[01/15] mean_loss : 0.42, Perplexity : 1.52\n",
            "Finished batch loop...\n",
            "On epoch 2 out of 15\n",
            "Starting batch loop...\n",
            "[02/15] mean_loss : 0.39, Perplexity : 1.48\n",
            "[02/15] mean_loss : 0.30, Perplexity : 1.34\n",
            "[02/15] mean_loss : 0.30, Perplexity : 1.36\n",
            "[02/15] mean_loss : 0.31, Perplexity : 1.37\n",
            "[02/15] mean_loss : 0.40, Perplexity : 1.49\n",
            "[02/15] mean_loss : 0.39, Perplexity : 1.47\n",
            "[02/15] mean_loss : 0.44, Perplexity : 1.55\n",
            "Finished batch loop...\n",
            "On epoch 3 out of 15\n",
            "Starting batch loop...\n",
            "[03/15] mean_loss : 0.34, Perplexity : 1.40\n",
            "[03/15] mean_loss : 0.30, Perplexity : 1.34\n",
            "[03/15] mean_loss : 0.29, Perplexity : 1.34\n",
            "[03/15] mean_loss : 0.30, Perplexity : 1.35\n",
            "[03/15] mean_loss : 0.28, Perplexity : 1.33\n",
            "[03/15] mean_loss : 0.27, Perplexity : 1.31\n",
            "[03/15] mean_loss : 0.34, Perplexity : 1.40\n",
            "Finished batch loop...\n",
            "On epoch 4 out of 15\n",
            "Starting batch loop...\n",
            "[04/15] mean_loss : 0.24, Perplexity : 1.27\n",
            "[04/15] mean_loss : 0.18, Perplexity : 1.19\n",
            "[04/15] mean_loss : 0.23, Perplexity : 1.26\n",
            "[04/15] mean_loss : 0.23, Perplexity : 1.26\n",
            "[04/15] mean_loss : 0.20, Perplexity : 1.22\n",
            "[04/15] mean_loss : 0.16, Perplexity : 1.17\n",
            "[04/15] mean_loss : 0.20, Perplexity : 1.23\n",
            "Finished batch loop...\n",
            "On epoch 5 out of 15\n",
            "Starting batch loop...\n",
            "[05/15] mean_loss : 0.19, Perplexity : 1.21\n",
            "[05/15] mean_loss : 0.17, Perplexity : 1.19\n",
            "[05/15] mean_loss : 0.14, Perplexity : 1.15\n",
            "[05/15] mean_loss : 0.10, Perplexity : 1.11\n",
            "[05/15] mean_loss : 0.13, Perplexity : 1.14\n",
            "[05/15] mean_loss : 0.16, Perplexity : 1.18\n",
            "[05/15] mean_loss : 0.12, Perplexity : 1.13\n",
            "Finished batch loop...\n",
            "On epoch 6 out of 15\n",
            "Starting batch loop...\n",
            "[06/15] mean_loss : 0.09, Perplexity : 1.09\n",
            "[06/15] mean_loss : 0.08, Perplexity : 1.08\n",
            "[06/15] mean_loss : 0.09, Perplexity : 1.09\n",
            "[06/15] mean_loss : 0.06, Perplexity : 1.06\n",
            "[06/15] mean_loss : 0.09, Perplexity : 1.10\n",
            "[06/15] mean_loss : 0.11, Perplexity : 1.11\n",
            "[06/15] mean_loss : 0.11, Perplexity : 1.12\n",
            "Finished batch loop...\n",
            "On epoch 7 out of 15\n",
            "Starting batch loop...\n",
            "[07/15] mean_loss : 0.07, Perplexity : 1.08\n",
            "[07/15] mean_loss : 0.05, Perplexity : 1.05\n",
            "[07/15] mean_loss : 0.07, Perplexity : 1.08\n",
            "[07/15] mean_loss : 0.07, Perplexity : 1.07\n",
            "[07/15] mean_loss : 0.11, Perplexity : 1.11\n",
            "[07/15] mean_loss : 0.05, Perplexity : 1.05\n",
            "[07/15] mean_loss : 0.08, Perplexity : 1.08\n",
            "Finished batch loop...\n",
            "On epoch 8 out of 15\n",
            "Starting batch loop...\n",
            "[08/15] mean_loss : 0.08, Perplexity : 1.08\n",
            "[08/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[08/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[08/15] mean_loss : 0.05, Perplexity : 1.05\n",
            "[08/15] mean_loss : 0.05, Perplexity : 1.05\n",
            "[08/15] mean_loss : 0.05, Perplexity : 1.06\n",
            "[08/15] mean_loss : 0.06, Perplexity : 1.06\n",
            "Finished batch loop...\n",
            "On epoch 9 out of 15\n",
            "Starting batch loop...\n",
            "[09/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[09/15] mean_loss : 0.05, Perplexity : 1.05\n",
            "[09/15] mean_loss : 0.04, Perplexity : 1.05\n",
            "[09/15] mean_loss : 0.06, Perplexity : 1.06\n",
            "[09/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[09/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[09/15] mean_loss : 0.06, Perplexity : 1.06\n",
            "Finished batch loop...\n",
            "On epoch 10 out of 15\n",
            "Starting batch loop...\n",
            "[10/15] mean_loss : 0.05, Perplexity : 1.05\n",
            "[10/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[10/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[10/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[10/15] mean_loss : 0.05, Perplexity : 1.06\n",
            "[10/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[10/15] mean_loss : 0.06, Perplexity : 1.06\n",
            "Finished batch loop...\n",
            "On epoch 11 out of 15\n",
            "Starting batch loop...\n",
            "[11/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[11/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[11/15] mean_loss : 0.05, Perplexity : 1.06\n",
            "[11/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[11/15] mean_loss : 0.02, Perplexity : 1.02\n",
            "[11/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[11/15] mean_loss : 0.04, Perplexity : 1.05\n",
            "Finished batch loop...\n",
            "On epoch 12 out of 15\n",
            "Starting batch loop...\n",
            "[12/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[12/15] mean_loss : 0.02, Perplexity : 1.02\n",
            "[12/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[12/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[12/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[12/15] mean_loss : 0.02, Perplexity : 1.02\n",
            "[12/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "Finished batch loop...\n",
            "On epoch 13 out of 15\n",
            "Starting batch loop...\n",
            "[13/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[13/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[13/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[13/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[13/15] mean_loss : 0.02, Perplexity : 1.02\n",
            "[13/15] mean_loss : 0.02, Perplexity : 1.02\n",
            "[13/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "Finished batch loop...\n",
            "On epoch 14 out of 15\n",
            "Starting batch loop...\n",
            "[14/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[14/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[14/15] mean_loss : 0.02, Perplexity : 1.02\n",
            "[14/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[14/15] mean_loss : 0.04, Perplexity : 1.04\n",
            "[14/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[14/15] mean_loss : 0.05, Perplexity : 1.06\n",
            "Finished batch loop...\n",
            "On epoch 15 out of 15\n",
            "Starting batch loop...\n",
            "[15/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[15/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[15/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[15/15] mean_loss : 0.02, Perplexity : 1.02\n",
            "[15/15] mean_loss : 0.02, Perplexity : 1.02\n",
            "[15/15] mean_loss : 0.03, Perplexity : 1.03\n",
            "[15/15] mean_loss : 0.04, Perplexity : 1.05\n",
            "Finished batch loop...\n",
            "PREDICTING LABELS NOW\n",
            "FINISHED PREDICTING LABELS\n",
            "Accuracy:\n",
            "0.8568181818181818\n",
            "F1:\n",
            "0.580958715665674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAFnCAYAAACy1GJbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Iuuf-VBCOfNg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "print(\"PREDICTING TESTING LABELS NOW\")\n",
        "for testing_input in testing_data_tensor:\n",
        "    model.zero_grad()\n",
        "    prediction_val = predict_value(testing_input.unsqueeze(1).to(device))\n",
        "    predicted_label = \"TIN\" if prediction_val == 1 else \"UNT\"\n",
        "    preds.append(predicted_label)\n",
        "print(\"FINISHED TESTING PREDICTING LABELS\")\n",
        "\n",
        "# Write predictions into output csv file                               \n",
        "csvData = []\n",
        "testing_id_values = testing_dataset['id']\n",
        "\n",
        "print(len(testing_data_tensor))\n",
        "print(len(testing_id_values))\n",
        "for i, id_val in enumerate(testing_id_values):                                 \n",
        "   csvData.append([id_val, preds[i]])                                 \n",
        "with open('predictions.csv', 'w') as csvFile:                          \n",
        "   writer = csv.writer(csvFile)                                       \n",
        "   writer.writerows(csvData)\n",
        "\n",
        "files.download('predictions.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}